from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, split, col, trim, avg, count, round

# === Kh·ªüi t·∫°o SparkSession ===
spark = SparkSession.builder \
    .appName("Average Score by Genre") \
    .getOrCreate()

# === ƒê·ªçc d·ªØ li·ªáu ===
input_path = "hdfs:///user/hadoopcloud/movies"
df = spark.read.csv(input_path, header=False, inferSchema=True)

# ƒê·ªïi t√™n c·ªôt n·∫øu c·∫ßn (gi·∫£ s·ª≠ d·ªØ li·ªáu c√≥ format JSON nh∆∞ trong v√≠ d·ª• tr∆∞·ªõc)
df = df.toDF("Movie_Name", "Release_Year", "Metascore", "Critic_Reviews", "User_Score", "User_Ratings","Duration_Minutes", "Genre", "Average")

df = df.filter((col("Genre").isNotNull()) & (col("Metascore").isNotNull()) & (col("User_Score").isNotNull()))
# === Map phase: t√°ch genre th√†nh t·ª´ng d√≤ng ri√™ng ===
genre_df = df.withColumn("Genre", explode(split(col("Genre"), r"\||,")))  # h·ªó tr·ª£ c·∫£ "|" ho·∫∑c ","
genre_df = genre_df.withColumn("Genre", trim(col("Genre"))).filter(col("Genre") != "")

# === Reduce phase: t√≠nh trung b√¨nh Metascore v√† ƒë·∫øm s·ªë phim cho m·ªói th·ªÉ lo·∫°i ===
result = genre_df.groupBy("Genre").agg(
    round(avg("Metascore"), 2).alias("Avg_Metascore"),
    round(avg("User_Score"), 2).alias("Avg_User_Score"),
    count("*").alias("Movie_Count")   # üßÆ ƒê·∫øm s·ªë l∆∞·ª£ng phim trong m·ªói th·ªÉ lo·∫°i
).orderBy(col("Movie_Count").desc(), col("Avg_Metascore").desc(), col("Avg_User_Score").desc())

# === Ghi k·∫øt qu·∫£ ra HDFS ===
output_path = "hdfs:///user/hadoopcloud/output/genre_score"
result.coalesce(1).write.mode("overwrite").option("header", True).csv(output_path)

print("‚úÖ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i th∆∞ m·ª•c:", output_path)

spark.stop()